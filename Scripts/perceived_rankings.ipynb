{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import friedmanchisquare, kruskal, mannwhitneyu, wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def calculate_metrics():\n",
    "    \"\"\"\n",
    "    Calculate metrics from the CSV files and save results to the specified directory.\n",
    "    Returns the base directory path where files are saved.\n",
    "    \"\"\"\n",
    "    # Read the CSV files\n",
    "    test_df = pd.read_csv('../data/perceived_ranking_results/raw_data/RankingTest_with_numeric.csv')\n",
    "    practice_df = pd.read_csv('../data/perceived_ranking_results/raw_data/RankingPractice_with_numeric.csv')\n",
    "    \n",
    "    # Define metrics for each dataset\n",
    "    test_metrics = ['Difficulty', 'Satisfaction', 'Stress']\n",
    "    practice_metrics = ['Difficulty', 'Satisfaction', 'Stress', 'Helpfulness', 'Adherence']\n",
    "    \n",
    "    # Create base directory and results subdirectory if they don't exist\n",
    "    base_dir = \"../data/perceived_ranking_results/\"\n",
    "    results_dir = os.path.join(base_dir, \"results\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Create mean tables and save as CSV\n",
    "    # For test tasks\n",
    "    test_means = []\n",
    "    for metric in test_metrics:\n",
    "        pivot = pd.pivot_table(test_df, \n",
    "                             values=metric, \n",
    "                             index='Group_ID', \n",
    "                             columns='Task_ID', \n",
    "                             aggfunc='mean').round(2)\n",
    "        pivot.index = [f'Group {i}' for i in pivot.index]\n",
    "        test_means.append(pivot)\n",
    "        \n",
    "        # Save to CSV in results directory\n",
    "        file_path = os.path.join(results_dir, f\"test_tasks_{metric.lower()}_means.csv\")\n",
    "        pivot.to_csv(file_path)\n",
    "        # print(f\"Saved to {file_path}\")\n",
    "    \n",
    "    # For practice tasks\n",
    "    practice_means = []\n",
    "    for metric in practice_metrics:\n",
    "        pivot = pd.pivot_table(practice_df, \n",
    "                             values=metric, \n",
    "                             index='Group_ID', \n",
    "                             columns='Task_ID', \n",
    "                             aggfunc='mean').round(2)\n",
    "        pivot.index = [f'Group {i}' for i in pivot.index]\n",
    "        practice_means.append(pivot)\n",
    "        \n",
    "        # Save to CSV in results directory\n",
    "        file_path = os.path.join(results_dir, f\"practice_tasks_{metric.lower()}_means.csv\")\n",
    "        pivot.to_csv(file_path)\n",
    "        # print(f\"Saved to {file_path}\")\n",
    "    \n",
    "    # Print tables\n",
    "    '''\n",
    "    print(\"Test Tasks Mean Values:\")\n",
    "    for metric, df in zip(test_metrics, test_means):\n",
    "        print(f\"\\n{metric} Means:\")\n",
    "        print(df)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    print(\"\\nPractice Tasks Mean Values:\")\n",
    "    for metric, df in zip(practice_metrics, practice_means):\n",
    "        print(f\"\\n{metric} Means:\")\n",
    "        print(df)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "    '''\n",
    "    # Create comprehensive dataframes with all metrics for easier analysis\n",
    "    \n",
    "    # For test tasks - combine all metrics into one dataframe\n",
    "    test_all_metrics = pd.DataFrame()\n",
    "    for metric, pivot_df in zip(test_metrics, test_means):\n",
    "        # Reset index to get Group as a column\n",
    "        temp_df = pivot_df.reset_index()\n",
    "        # Melt to get Task_ID as a column\n",
    "        temp_df = temp_df.melt(id_vars='index', var_name='Task_ID', value_name=metric)\n",
    "        temp_df = temp_df.rename(columns={'index': 'Group'})\n",
    "        \n",
    "        if test_all_metrics.empty:\n",
    "            test_all_metrics = temp_df\n",
    "        else:\n",
    "            # Merge with existing dataframe\n",
    "            test_all_metrics = pd.merge(test_all_metrics, temp_df, on=['Group', 'Task_ID'])\n",
    "    \n",
    "    # Save the combined test metrics dataframe\n",
    "    file_path = os.path.join(results_dir, \"test_tasks_all_metrics.csv\")\n",
    "    test_all_metrics.to_csv(file_path, index=False)\n",
    "    # print(f\"Saved combined test metrics to {file_path}\")\n",
    "    \n",
    "    # For practice tasks - combine all metrics into one dataframe\n",
    "    practice_all_metrics = pd.DataFrame()\n",
    "    for metric, pivot_df in zip(practice_metrics, practice_means):\n",
    "        # Reset index to get Group as a column\n",
    "        temp_df = pivot_df.reset_index()\n",
    "        # Melt to get Task_ID as a column\n",
    "        temp_df = temp_df.melt(id_vars='index', var_name='Task_ID', value_name=metric)\n",
    "        temp_df = temp_df.rename(columns={'index': 'Group'})\n",
    "        \n",
    "        if practice_all_metrics.empty:\n",
    "            practice_all_metrics = temp_df\n",
    "        else:\n",
    "            # Merge with existing dataframe\n",
    "            practice_all_metrics = pd.merge(practice_all_metrics, temp_df, on=['Group', 'Task_ID'])\n",
    "    \n",
    "    # Save the combined practice metrics dataframe\n",
    "    file_path = os.path.join(results_dir, \"practice_tasks_all_metrics.csv\")\n",
    "    practice_all_metrics.to_csv(file_path, index=False)\n",
    "    # print(f\"Saved combined practice metrics to {file_path}\")\n",
    "    \n",
    "    return base_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_metrics(base_dir=None):\n",
    "    \"\"\"\n",
    "    Create visualizations based on the saved metrics files with enhanced formatting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_dir : str\n",
    "        Base directory where the figures will be saved.\n",
    "        If None, uses the default directory.\n",
    "    \"\"\"\n",
    "    if base_dir is None:\n",
    "        base_dir = \"../data/perceived_ranking_results/\"\n",
    "    \n",
    "    # Create figures directory if it doesn't exist\n",
    "    figures_dir = os.path.join(base_dir, \"figures\")\n",
    "    os.makedirs(figures_dir, exist_ok=True)\n",
    "    \n",
    "    # Load data from the original files\n",
    "\n",
    "    test_df = pd.read_csv('../data/perceived_ranking_results/raw_data/RankingTest_with_numeric.csv')\n",
    "    practice_df = pd.read_csv('../data/perceived_ranking_results/raw_data/RankingPractice_with_numeric.csv')\n",
    "    \n",
    "    # Define metrics for each dataset\n",
    "    test_metrics = ['Difficulty', 'Satisfaction', 'Stress']\n",
    "    practice_metrics = ['Difficulty', 'Satisfaction', 'Stress', 'Helpfulness', 'Adherence']\n",
    "    \n",
    "    # Calculate averages for T1-T5 for each group and metric\n",
    "    test_avg_by_group = {}\n",
    "    for metric in test_metrics:\n",
    "        test_avg_by_group[metric] = {}\n",
    "        for group_id in [1, 2, 3, 4]:\n",
    "            # Filter by group and only include T1-T5 (exclude T0)\n",
    "            group_data = test_df[(test_df['Group_ID'] == group_id) & \n",
    "                                (test_df['Task_ID'].isin(['T1', 'T2', 'T3', 'T4', 'T5']))]\n",
    "            # Calculate the average\n",
    "            avg_value = group_data[metric].mean().round(3)\n",
    "            test_avg_by_group[metric][group_id] = avg_value\n",
    "            print(f\"Average {metric} for Group {group_id} (T1-T5): {avg_value}\")\n",
    "    \n",
    "    # Calculate averages for practice tasks\n",
    "    practice_avg_by_group = {}\n",
    "    for metric in practice_metrics:\n",
    "        practice_avg_by_group[metric] = {}\n",
    "        for group_id in [1, 2, 3, 4]:\n",
    "            group_data = practice_df[practice_df['Group_ID'] == group_id]\n",
    "            avg_value = group_data[metric].mean().round(3)\n",
    "            practice_avg_by_group[metric][group_id] = avg_value\n",
    "            print(f\"Average {metric} for Group {group_id} (All Practice): {avg_value}\")\n",
    "    \n",
    "    # Define colorblind-friendly colors\n",
    "    colors = ['#E69F00',  # orange\n",
    "              '#56B4E9',  # light blue \n",
    "              '#009E73',  # green\n",
    "              '#CC79A7']  # pink\n",
    "    \n",
    "    # Define markers for each group\n",
    "    markers = ['o',    # circle\n",
    "              '^',    # triangle up \n",
    "              's',    # square\n",
    "              'D']    # diamond\n",
    "    \n",
    "    # Define different line styles for average lines\n",
    "    avg_styles = [(0, (1, 1)),      # dotted\n",
    "                  (0, (5, 5)),      # dashed\n",
    "                  (0, (3, 1, 1, 1)), # dash-dot\n",
    "                  (0, (8, 5))]      # long dash\n",
    "    \n",
    "    # Define line properties for average lines\n",
    "    linewidth_avg = 3.5  # Increased linewidth for average lines\n",
    "    alpha_avg = 0.8      # Increased opacity for better visibility\n",
    "    \n",
    "    # Define the order we want\n",
    "    groups_order = [(0, 'G1'), \n",
    "                    (1, 'G2'),\n",
    "                    (2, 'G3'),\n",
    "                    (3, 'G4')]\n",
    "    \n",
    "    # Define offsets for annotations to prevent overlapping\n",
    "    y_offsets = [0.1, -0.1, 0.15, -0.15]  # Different offsets for each group\n",
    "    \n",
    "    # Set consistent figure style\n",
    "    plt.rcParams.update({\n",
    "        'figure.facecolor': 'white',\n",
    "        'axes.facecolor': 'white',\n",
    "        'savefig.facecolor': 'white',\n",
    "        'font.size': 12,\n",
    "        'axes.labelsize': 12,\n",
    "        'axes.titlesize': 14,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10,\n",
    "        'legend.fontsize': 10\n",
    "    })\n",
    "    \n",
    "    # Import path effects for better text annotations\n",
    "    import matplotlib.patheffects as pe\n",
    "    \n",
    "    # =====================================================================\n",
    "    # Create visualization for test tasks metrics\n",
    "    # =====================================================================\n",
    "    for metric in test_metrics:\n",
    "        fig, ax = plt.subplots(figsize=(10, 7))\n",
    "        \n",
    "        # Task IDs - convert to strings before sorting to handle mixed types\n",
    "        task_ids = sorted(test_df['Task_ID'].unique(), key=str)\n",
    "        # Create positions dictionary for consistent x-axis spacing\n",
    "        positions = {task: i for i, task in enumerate(task_ids)}\n",
    "        \n",
    "        for idx, (group_idx, group_name) in enumerate(groups_order):\n",
    "            group_id = idx + 1  # Convert to 1-based index for data filtering\n",
    "            \n",
    "            # Get the data for this group and metric\n",
    "            group_data = test_df[test_df['Group_ID'] == group_id]\n",
    "            means = group_data.groupby('Task_ID')[metric].mean()\n",
    "            \n",
    "            # Plot the actual data points with custom positions\n",
    "            x_values = [positions[t] for t in means.index]\n",
    "            line = ax.plot(x_values, means.values,\n",
    "                          marker=markers[group_idx],\n",
    "                          linewidth=2,\n",
    "                          label=group_name,\n",
    "                          color=colors[group_idx],\n",
    "                          markersize=8)[0]\n",
    "                          \n",
    "            # Add value annotations with white outlines - positioned above/below markers\n",
    "            for x, y in zip(x_values, means.values):\n",
    "                # Use larger vertical offset to avoid overlap with markers\n",
    "                vertical_offset = 15 if y_offsets[idx] > 0 else -15\n",
    "                \n",
    "                ax.annotate(f'{y:.1f}',\n",
    "                           (x, y),\n",
    "                           textcoords=\"offset points\",\n",
    "                           xytext=(0, vertical_offset),  # Fixed vertical offset\n",
    "                           ha='center',\n",
    "                           va='bottom' if y_offsets[idx] > 0 else 'top',\n",
    "                           color=colors[group_idx],\n",
    "                           fontsize=9,\n",
    "                           fontweight='bold',\n",
    "                           path_effects=[pe.withStroke(linewidth=2, foreground='white')])\n",
    "            \n",
    "            # Add average line (T1-T5)\n",
    "            avg_value = test_avg_by_group[metric][group_id]\n",
    "            avg_line = ax.axhline(y=avg_value,\n",
    "                                 color=colors[group_idx],\n",
    "                                 linestyle=avg_styles[group_idx],\n",
    "                                 alpha=alpha_avg,\n",
    "                                 linewidth=linewidth_avg,\n",
    "                                 label=f\"{group_name} Avg\")\n",
    "                                 \n",
    "            # Add text annotation for average value directly on the plot\n",
    "            # Position at the right edge of the plot\n",
    "            ax.annotate(f'{avg_value:.1f}',\n",
    "                      xy=(1.01, avg_value),  # Just outside the right edge\n",
    "                      xycoords=('axes fraction', 'data'),\n",
    "                      fontsize=10,\n",
    "                      color=colors[group_idx],\n",
    "                      fontweight='bold',\n",
    "                      va='center')\n",
    "        \n",
    "        # Add vertical grid lines for task positions\n",
    "        for task, pos in positions.items():\n",
    "            ax.axvline(x=pos, color='gray', linestyle='-', alpha=0.1)\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks(list(positions.values()))\n",
    "        ax.set_xticklabels(list(positions.keys()))\n",
    "        \n",
    "        # Set y-axis range starting from 1 with whole number ticks\n",
    "        ax.set_ylim(1, 5.2)  # 5-point scale starting from 1\n",
    "        ax.set_yticks([1, 2, 3, 4, 5])  # Set y-ticks to whole numbers only\n",
    "        \n",
    "        # Only show horizontal grid lines\n",
    "        ax.yaxis.grid(True, linestyle='-', alpha=0.2)\n",
    "        ax.xaxis.grid(False)\n",
    "        \n",
    "        # Set labels and title with improved formatting\n",
    "        ax.set_title(f'Test Tasks: {metric} Scores by Group', pad=20, fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Task ID', fontsize=12)\n",
    "        ax.set_ylabel(f'{metric} Score', fontsize=12)\n",
    "        \n",
    "        # Create better positioned legend\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        # Separate group lines from average lines\n",
    "        group_handles = handles[:4]\n",
    "        group_labels = labels[:4]\n",
    "        avg_handles = handles[4:]\n",
    "        avg_labels = labels[4:]\n",
    "        \n",
    "        # Create legend with two columns - first for groups, then for averages\n",
    "        all_handles = group_handles + avg_handles\n",
    "        all_labels = group_labels + avg_labels\n",
    "        ax.legend(all_handles, all_labels,\n",
    "                 fontsize=10,\n",
    "                 ncol=1,\n",
    "                 loc='center left',\n",
    "                 bbox_to_anchor=(1.05, 0.5),\n",
    "                 handlelength=3,\n",
    "                 borderaxespad=0.)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        fig_path = os.path.join(figures_dir, f'test_tasks_{metric.lower()}.png')\n",
    "        plt.savefig(fig_path, bbox_inches='tight', dpi=300, facecolor='white')\n",
    "        print(f\"Saved individual {metric} test task visualization to {fig_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    # =====================================================================\n",
    "    # Create visualization for practice tasks metrics\n",
    "    # =====================================================================\n",
    "    for metric in practice_metrics:\n",
    "        fig, ax = plt.subplots(figsize=(10, 7))\n",
    "        \n",
    "        # Task IDs - convert to strings before sorting to handle mixed types\n",
    "        task_ids = sorted(practice_df['Task_ID'].unique(), key=str)\n",
    "        # Create positions dictionary for consistent x-axis spacing\n",
    "        positions = {task: i for i, task in enumerate(task_ids)}\n",
    "        \n",
    "        for idx, (group_idx, group_name) in enumerate(groups_order):\n",
    "            group_id = idx + 1  # Convert to 1-based index for data filtering\n",
    "            \n",
    "            # Get the data for this group and metric\n",
    "            group_data = practice_df[practice_df['Group_ID'] == group_id]\n",
    "            means = group_data.groupby('Task_ID')[metric].mean()\n",
    "            \n",
    "            # Plot the actual data points with custom positions\n",
    "            x_values = [positions[t] for t in means.index]\n",
    "            line = ax.plot(x_values, means.values,\n",
    "                          marker=markers[group_idx],\n",
    "                          linewidth=2,\n",
    "                          label=group_name,\n",
    "                          color=colors[group_idx],\n",
    "                          markersize=8)[0]\n",
    "                          \n",
    "            # Add value annotations with white outlines - positioned above/below markers\n",
    "            for x, y in zip(x_values, means.values):\n",
    "                # Use larger vertical offset to avoid overlap with markers\n",
    "                vertical_offset = 15 if y_offsets[idx] > 0 else -15\n",
    "                \n",
    "                ax.annotate(f'{y:.1f}',\n",
    "                           (x, y),\n",
    "                           textcoords=\"offset points\",\n",
    "                           xytext=(0, vertical_offset),  # Fixed vertical offset\n",
    "                           ha='center',\n",
    "                           va='bottom' if y_offsets[idx] > 0 else 'top',\n",
    "                           color=colors[group_idx],\n",
    "                           fontsize=9,\n",
    "                           fontweight='bold',\n",
    "                           path_effects=[pe.withStroke(linewidth=2, foreground='white')])\n",
    "            \n",
    "            # Add average line for all practice tasks\n",
    "            avg_value = practice_avg_by_group[metric][group_id]\n",
    "            avg_line = ax.axhline(y=avg_value,\n",
    "                                 color=colors[group_idx],\n",
    "                                 linestyle=avg_styles[group_idx],\n",
    "                                 alpha=alpha_avg,\n",
    "                                 linewidth=linewidth_avg,\n",
    "                                 label=f\"{group_name} Avg\")\n",
    "                                 \n",
    "            # Add text annotation for average value directly on the plot\n",
    "            # Position at the right edge of the plot\n",
    "            ax.annotate(f'{avg_value:.1f}',\n",
    "                      xy=(1.01, avg_value),  # Just outside the right edge\n",
    "                      xycoords=('axes fraction', 'data'),\n",
    "                      fontsize=10,\n",
    "                      color=colors[group_idx],\n",
    "                      fontweight='bold',\n",
    "                      va='center')\n",
    "        \n",
    "        # Add vertical grid lines for task positions\n",
    "        for task, pos in positions.items():\n",
    "            ax.axvline(x=pos, color='gray', linestyle='-', alpha=0.1)\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks(list(positions.values()))\n",
    "        ax.set_xticklabels(list(positions.keys()))\n",
    "        \n",
    "        # Set y-axis range starting from 1 with whole number ticks\n",
    "        ax.set_ylim(1, 5.2)  # 5-point scale starting from 1\n",
    "        ax.set_yticks([1, 2, 3, 4, 5])  # Set y-ticks to whole numbers only\n",
    "        \n",
    "        # Only show horizontal grid lines\n",
    "        ax.yaxis.grid(True, linestyle='-', alpha=0.2)\n",
    "        ax.xaxis.grid(False)\n",
    "        \n",
    "        # Set labels and title with improved formatting\n",
    "        ax.set_title(f'Practice Tasks: {metric} Scores by Group', pad=20, fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Task ID', fontsize=12)\n",
    "        ax.set_ylabel(f'{metric} Score', fontsize=12)\n",
    "        \n",
    "        # Create better positioned legend\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        # Separate group lines from average lines\n",
    "        group_handles = handles[:4]\n",
    "        group_labels = labels[:4]\n",
    "        avg_handles = handles[4:]\n",
    "        avg_labels = labels[4:]\n",
    "        \n",
    "        # Create legend with two columns - first for groups, then for averages\n",
    "        all_handles = group_handles + avg_handles\n",
    "        all_labels = group_labels + avg_labels\n",
    "        ax.legend(all_handles, all_labels,\n",
    "                 fontsize=10,\n",
    "                 ncol=1,\n",
    "                 loc='center left',\n",
    "                 bbox_to_anchor=(1.05, 0.5),\n",
    "                 handlelength=3,\n",
    "                 borderaxespad=0.)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        fig_path = os.path.join(figures_dir, f'practice_tasks_{metric.lower()}.png')\n",
    "        plt.savefig(fig_path, bbox_inches='tight', dpi=300, facecolor='white')\n",
    "        print(f\"Saved individual {metric} practice task visualization to {fig_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    # =====================================================================\n",
    "    # Create combined visualizations (panels of metrics)\n",
    "    # =====================================================================\n",
    "    \n",
    "    # Create subplots for test tasks\n",
    "    fig1, axes1 = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig1.suptitle('Test Tasks Metrics by Group', fontsize=16, fontweight='bold', y=1.05)\n",
    "    \n",
    "    # Plot test metrics\n",
    "    for i, metric in enumerate(test_metrics):\n",
    "        ax = axes1[i]\n",
    "        \n",
    "        # Task IDs - convert to strings before sorting to handle mixed types\n",
    "        task_ids = sorted(test_df['Task_ID'].unique(), key=str)\n",
    "        # Create positions dictionary for consistent x-axis spacing\n",
    "        positions = {task: i for i, task in enumerate(task_ids)}\n",
    "        \n",
    "        for idx, (group_idx, group_name) in enumerate(groups_order):\n",
    "            group_id = idx + 1  # Convert to 1-based index for data filtering\n",
    "            \n",
    "            # Get the data for this group and metric\n",
    "            group_data = test_df[test_df['Group_ID'] == group_id]\n",
    "            means = group_data.groupby('Task_ID')[metric].mean()\n",
    "            \n",
    "            # Plot the actual data points with custom positions\n",
    "            x_values = [positions[t] for t in means.index]\n",
    "            line = ax.plot(x_values, means.values,\n",
    "                          marker=markers[group_idx],\n",
    "                          linewidth=2,\n",
    "                          label=group_name,\n",
    "                          color=colors[group_idx],\n",
    "                          markersize=6)[0]  # Smaller markers for panel\n",
    "            \n",
    "            # Add average line (T1-T5)\n",
    "            avg_value = test_avg_by_group[metric][group_id]\n",
    "            avg_line = ax.axhline(y=avg_value,\n",
    "                                 color=colors[group_idx],\n",
    "                                 linestyle=avg_styles[group_idx],\n",
    "                                 alpha=alpha_avg,\n",
    "                                 linewidth=linewidth_avg)\n",
    "                                 \n",
    "            # Add text annotation for average value at the right edge\n",
    "            ax.annotate(f'{avg_value:.1f}',\n",
    "                      xy=(1.01, avg_value),\n",
    "                      xycoords=('axes fraction', 'data'),\n",
    "                      fontsize=8,\n",
    "                      color=colors[group_idx],\n",
    "                      fontweight='bold',\n",
    "                      va='center')\n",
    "        \n",
    "        # Add vertical grid lines for task positions\n",
    "        for task, pos in positions.items():\n",
    "            ax.axvline(x=pos, color='gray', linestyle='-', alpha=0.1)\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks(list(positions.values()))\n",
    "        ax.set_xticklabels(list(positions.keys()))\n",
    "        \n",
    "        # Set y-axis range with some padding\n",
    "        ax.set_ylim(0, 5.2)  # 5-point scale with a little padding\n",
    "        \n",
    "        # Only show horizontal grid lines\n",
    "        ax.yaxis.grid(True, linestyle='-', alpha=0.2)\n",
    "        ax.xaxis.grid(False)\n",
    "        \n",
    "        # Set labels and title with improved formatting\n",
    "        ax.set_title(f'{metric} Scores', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Task ID', fontsize=10)\n",
    "        ax.set_ylabel(f'{metric} Score', fontsize=10)\n",
    "        \n",
    "        # Only add legend to the first subplot\n",
    "        if i == 0:\n",
    "            ax.legend(fontsize=9, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(figures_dir, 'test_tasks_metrics.png')\n",
    "    plt.savefig(fig_path, bbox_inches='tight', dpi=300, facecolor='white')\n",
    "    print(f\"Saved test tasks visualization to {fig_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Create subplots for practice tasks\n",
    "    fig2, axes2 = plt.subplots(1, 5, figsize=(25, 5))\n",
    "    fig2.suptitle('Practice Tasks Metrics by Group', fontsize=16, fontweight='bold', y=1.05)\n",
    "    \n",
    "    # Plot practice metrics\n",
    "    for i, metric in enumerate(practice_metrics):\n",
    "        ax = axes2[i]\n",
    "        \n",
    "        # Task IDs - convert to strings before sorting to handle mixed types\n",
    "        task_ids = sorted(practice_df['Task_ID'].unique(), key=str)\n",
    "        # Create positions dictionary for consistent x-axis spacing\n",
    "        positions = {task: i for i, task in enumerate(task_ids)}\n",
    "        \n",
    "        for idx, (group_idx, group_name) in enumerate(groups_order):\n",
    "            group_id = idx + 1  # Convert to 1-based index for data filtering\n",
    "            \n",
    "            # Get the data for this group and metric\n",
    "            group_data = practice_df[practice_df['Group_ID'] == group_id]\n",
    "            means = group_data.groupby('Task_ID')[metric].mean()\n",
    "            \n",
    "            # Plot the actual data points with custom positions\n",
    "            x_values = [positions[t] for t in means.index]\n",
    "            line = ax.plot(x_values, means.values,\n",
    "                          marker=markers[group_idx],\n",
    "                          linewidth=2,\n",
    "                          label=group_name,\n",
    "                          color=colors[group_idx],\n",
    "                          markersize=6)[0]  # Smaller markers for panel\n",
    "            \n",
    "            # Add average line for all practice tasks\n",
    "            avg_value = practice_avg_by_group[metric][group_id]\n",
    "            avg_line = ax.axhline(y=avg_value,\n",
    "                                 color=colors[group_idx],\n",
    "                                 linestyle=avg_styles[group_idx],\n",
    "                                 alpha=alpha_avg,\n",
    "                                 linewidth=linewidth_avg)\n",
    "                                 \n",
    "            # Add text annotation for average value at the right edge\n",
    "            ax.annotate(f'{avg_value:.1f}',\n",
    "                      xy=(1.01, avg_value),\n",
    "                      xycoords=('axes fraction', 'data'),\n",
    "                      fontsize=8,\n",
    "                      color=colors[group_idx],\n",
    "                      fontweight='bold',\n",
    "                      va='center')\n",
    "        \n",
    "        # Add vertical grid lines for task positions\n",
    "        for task, pos in positions.items():\n",
    "            ax.axvline(x=pos, color='gray', linestyle='-', alpha=0.1)\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks(list(positions.values()))\n",
    "        ax.set_xticklabels(list(positions.keys()))\n",
    "        \n",
    "        # Set y-axis range with some padding\n",
    "        ax.set_ylim(0, 5.2)  # 5-point scale with a little padding\n",
    "        \n",
    "        # Only show horizontal grid lines\n",
    "        ax.yaxis.grid(True, linestyle='-', alpha=0.2)\n",
    "        ax.xaxis.grid(False)\n",
    "        \n",
    "        # Set labels and title with improved formatting\n",
    "        ax.set_title(f'{metric} Scores', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Task ID', fontsize=10)\n",
    "        ax.set_ylabel(f'{metric} Score', fontsize=10)\n",
    "        \n",
    "        # Only add legend to the first subplot\n",
    "        if i == 0:\n",
    "            ax.legend(fontsize=9, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(figures_dir, 'practice_tasks_metrics.png')\n",
    "    plt.savefig(fig_path, bbox_inches='tight', dpi=300, facecolor='white')\n",
    "    print(f\"Saved practice tasks visualization to {fig_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nAll visualizations have been saved to the directory:\", figures_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Calculating and saving metrics...\n",
      "\n",
      "Step 2: Creating visualizations...\n",
      "Average Difficulty for Group 1 (T1-T5): 2.979\n",
      "Average Difficulty for Group 2 (T1-T5): 3.156\n",
      "Average Difficulty for Group 3 (T1-T5): 3.205\n",
      "Average Difficulty for Group 4 (T1-T5): 2.408\n",
      "Average Satisfaction for Group 1 (T1-T5): 3.447\n",
      "Average Satisfaction for Group 2 (T1-T5): 2.822\n",
      "Average Satisfaction for Group 3 (T1-T5): 3.14\n",
      "Average Satisfaction for Group 4 (T1-T5): 3.755\n",
      "Average Stress for Group 1 (T1-T5): 2.818\n",
      "Average Stress for Group 2 (T1-T5): 2.837\n",
      "Average Stress for Group 3 (T1-T5): 2.273\n",
      "Average Stress for Group 4 (T1-T5): 1.959\n",
      "Average Difficulty for Group 1 (All Practice): 2.771\n",
      "Average Difficulty for Group 2 (All Practice): 3.354\n",
      "Average Difficulty for Group 3 (All Practice): 3.304\n",
      "Average Difficulty for Group 4 (All Practice): 3.02\n",
      "Average Satisfaction for Group 1 (All Practice): 3.625\n",
      "Average Satisfaction for Group 2 (All Practice): 3.327\n",
      "Average Satisfaction for Group 3 (All Practice): 3.217\n",
      "Average Satisfaction for Group 4 (All Practice): 3.54\n",
      "Average Stress for Group 1 (All Practice): 2.447\n",
      "Average Stress for Group 2 (All Practice): 3.0\n",
      "Average Stress for Group 3 (All Practice): 2.0\n",
      "Average Stress for Group 4 (All Practice): 2.26\n",
      "Average Helpfulness for Group 1 (All Practice): 3.5\n",
      "Average Helpfulness for Group 2 (All Practice): 3.479\n",
      "Average Helpfulness for Group 3 (All Practice): 3.467\n",
      "Average Helpfulness for Group 4 (All Practice): 3.26\n",
      "Average Adherence for Group 1 (All Practice): 4.188\n",
      "Average Adherence for Group 2 (All Practice): 3.102\n",
      "Average Adherence for Group 3 (All Practice): 3.478\n",
      "Average Adherence for Group 4 (All Practice): 3.12\n",
      "Saved individual Difficulty test task visualization to ../data/perceived_ranking_results/figures/test_tasks_difficulty.png\n",
      "Saved individual Satisfaction test task visualization to ../data/perceived_ranking_results/figures/test_tasks_satisfaction.png\n",
      "Saved individual Stress test task visualization to ../data/perceived_ranking_results/figures/test_tasks_stress.png\n",
      "Saved individual Difficulty practice task visualization to ../data/perceived_ranking_results/figures/practice_tasks_difficulty.png\n",
      "Saved individual Satisfaction practice task visualization to ../data/perceived_ranking_results/figures/practice_tasks_satisfaction.png\n",
      "Saved individual Stress practice task visualization to ../data/perceived_ranking_results/figures/practice_tasks_stress.png\n",
      "Saved individual Helpfulness practice task visualization to ../data/perceived_ranking_results/figures/practice_tasks_helpfulness.png\n",
      "Saved individual Adherence practice task visualization to ../data/perceived_ranking_results/figures/practice_tasks_adherence.png\n",
      "Saved test tasks visualization to ../data/perceived_ranking_results/figures/test_tasks_metrics.png\n",
      "Saved practice tasks visualization to ../data/perceived_ranking_results/figures/practice_tasks_metrics.png\n",
      "\n",
      "All visualizations have been saved to the directory: ../data/perceived_ranking_results/figures\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "def run_analysis():\n",
    "    \"\"\"\n",
    "    Main function to run the complete analysis workflow\n",
    "    \"\"\"\n",
    "    print(\"Step 1: Calculating and saving metrics...\")\n",
    "    base_dir = calculate_metrics()\n",
    "    \n",
    "    print(\"\\nStep 2: Creating visualizations...\")\n",
    "    visualize_metrics(base_dir)\n",
    "    \n",
    "    print(\"\\nAnalysis complete.\")\n",
    "\n",
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    run_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
